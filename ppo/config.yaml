train:
  train_name: PPO-train # Task/Run name
  device: cuda:0 # Device
  lr: 0.0026 # Learning rate
  gamma: 0.99 # Discount factor
  gae_lambda: 0.95 # GAE lambda
  clip: 0.2 # PPO clip
  ent_coef: 0.001 # Entropy coefficient
  vf_coef: 2 # Value function coefficient
  max_grad_norm: 1 # Max gradient norm
  vloss_clip: True
  vloss_clip_coef: 0.2
  target_kl: True
  target_kl_coef: 0.2

  num_steps: 16
  total_timesteps: 300000000
  update_epochs: 4
  num_minibatches: 2
  save_interval: 1000

  env: 
    task: Anymal # Environment name
    num_envs: 4096 # Number of environments
    seed: 0 # Random seed
    sim_device: cuda:0
    rl_device: cuda:0
    graphics_device_id: 0
    headless: False
    multi_gpu: False
    force_render: True
  network:
    hidden_dim: 128